{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Denoising\n",
    "    - High-frequency noise (> 40 hz).\n",
    "    - Baseline wander (< 0.5 hz).\n",
    "2. Inversion correction\n",
    "    - If the signal is inverted, correct it.\n",
    "3. Downsampling\n",
    "    - From 300 hz to 100 hz.\n",
    "4. Continuous wavelet transform\n",
    "    - 0.5 - 40 hz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g113056077/.pyenv/versions/ecg-fl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import wfdb\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pywt\n",
    "from dataset_utils.transforms import RandomCrop\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "label_file = Path(config[\"data_preprocessing\"][\"label_file\"])\n",
    "src_dir = Path(config[\"data_preprocessing\"][\"src_dir\"])\n",
    "dst_dir = Path(config[\"data_preprocessing\"][\"dst_dir\"])\n",
    "\n",
    "src_freq = config[\"data_preprocessing\"].getint(\"src_freq\")\n",
    "dst_freq = config[\"data_preprocessing\"].getint(\"dst_freq\")\n",
    "dst_time = config[\"data_preprocessing\"].getint(\"dst_time\")\n",
    "\n",
    "cwt_freqs = np.linspace(40, 0.5, 31)\n",
    "norm_freqs = cwt_freqs / dst_freq\n",
    "scales = pywt.frequency2scale(\"morl\", norm_freqs)\n",
    "\n",
    "random_crop = RandomCrop(dst_time * dst_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signal(signal, freq, dst_freq):\n",
    "    # denoising\n",
    "    signal = nk.signal_filter(\n",
    "        signal,\n",
    "        sampling_rate=freq,\n",
    "        lowcut=0.5,\n",
    "        highcut=40,\n",
    "        method=\"butterworth\",\n",
    "        order=6,\n",
    "    )\n",
    "\n",
    "    # inversion correction\n",
    "    signal, _ = nk.ecg_invert(signal, sampling_rate=freq)\n",
    "\n",
    "    # downsampling\n",
    "    signal = nk.signal_resample(\n",
    "        signal, sampling_rate=freq, desired_sampling_rate=dst_freq\n",
    "    )\n",
    "    \n",
    "    # random crop\n",
    "    signal = random_crop(signal)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 8528/8528 [00:03<00:00, 2141.78it/s]\n",
      "Processing dataset: 100%|██████████| 8528/8528 [05:41<00:00, 25.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove existing files and directories\n",
    "shutil.rmtree(dst_dir, ignore_errors=True)\n",
    "\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# load the dataset\n",
    "dataset_df = pd.read_csv(label_file, header=None, names=[\"record_name\", \"label\"])\n",
    "\n",
    "# load all signals and labels\n",
    "all_signals: list[np.ndarray] = []\n",
    "all_labels: list[str] = dataset_df[\"label\"].tolist()\n",
    "for record_name in tqdm(\n",
    "    dataset_df[\"record_name\"],\n",
    "    total=len(dataset_df),\n",
    "    desc=f\"Loading dataset\",\n",
    "):\n",
    "    # load signal\n",
    "    signal, _ = wfdb.rdsamp(src_dir / record_name)\n",
    "    signal = np.squeeze(signal)\n",
    "    all_signals.append(signal)\n",
    "\n",
    "# process the dataset\n",
    "for record_name, label, signal in tqdm(\n",
    "    zip(dataset_df[\"record_name\"], all_labels, all_signals),\n",
    "    total=len(all_labels),\n",
    "    desc=f\"Processing dataset\",\n",
    "):\n",
    "    # preprocess the signal\n",
    "    preprocessed_signal = preprocess_signal(signal, src_freq, dst_freq)\n",
    "    \n",
    "    coefs, _ = pywt.cwt(preprocessed_signal, scales=scales, wavelet=\"morl\", sampling_period=1.0 / dst_freq)\n",
    "    preprocessed_signal = np.vstack([preprocessed_signal, coefs])\n",
    "    \n",
    "    np.savetxt(dst_dir / f\"{record_name}.csv\", preprocessed_signal, fmt=\"%f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
